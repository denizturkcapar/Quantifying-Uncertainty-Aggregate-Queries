{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "sys.path.insert(0, '../src')\n",
    "import one_to_n\n",
    "\n",
    "import datetime\n",
    "import textdistance\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_a = one_to_n.lat_convert_df(\"../Amazon-GoogleProducts/Amazon.csv\")\n",
    "\n",
    "table_b = one_to_n.lat_convert_df(\"../Amazon-GoogleProducts/GoogleProducts.csv\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "bipartite_graph_result = one_to_n.valcomp_treshold_updated_maximal_construct_graph(table_a, table_b, \"title\", 0.5)\n",
    "timing_tresh = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"---- Timing for Graph Construction with Treshold Constraint ----\")\n",
    "print(timing_tresh,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUM_edit_edge_weight(bip_graph):\n",
    "    for u,v,d in bip_graph.edges(data=True):\n",
    "        val_tuple_1 = u.split(\"_\")\n",
    "        val_tuple_2 = v.split(\"_\")\n",
    "        \n",
    "        val1 = re.sub(\"[^0-9]\", \"\", val_tuple_1[2])\n",
    "        val2 =re.sub(\"[^0-9]\", \"\", val_tuple_2[2])\n",
    "\n",
    "        d['weight'] = float(val1) + float(val2)\n",
    "\n",
    "    return bip_graph\n",
    "\n",
    "sum_weighted_graph = SUM_edit_edge_weight(bipartite_graph_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n 'SUM' MAXIMAL MATCHING:\")\n",
    "now = datetime.datetime.now()\n",
    "matching_set_maximal = nx.algorithms.matching.max_weight_matching(sum_weighted_graph)\n",
    "timing_match = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"---- Timing for Matching (Done on the graph constructed with the treshold constraint) ----\")\n",
    "print(timing_match,\"seconds\")\n",
    "print(\"The number of edges in the graph is:\", sum_weighted_graph.number_of_edges(), \"\\n\")\n",
    "\n",
    "\n",
    "# print(\"The Maximal Matching Set is:\", matching_set_maximal, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_edge = sum_weighted_graph.edges()\n",
    "for i in data_edge:\n",
    "    first = i[0].split(\"_\")[1]\n",
    "    second = i[1].split(\"_\")[1]\n",
    "    print((first, second))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Matching (Algorithm Using Max Matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_matching(sum_weighted_graph):\n",
    "\n",
    "    new_graph = sum_weighted_graph.copy()\n",
    "    max_weight = max([d['weight'] for u,v,d in new_graph.edges(data=True)])\n",
    "    for u,v,d in new_graph.edges(data=True):\n",
    "        d['weight'] = max_weight - d['weight']\n",
    "\n",
    "    matching_set_minimal = nx.algorithms.matching.max_weight_matching(new_graph)\n",
    "    return matching_set_minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n 'SUM' MINIMAL MATCHING RESULTS:\")\n",
    "print(nx.bipartite.is_bipartite(sum_weighted_graph))\n",
    "now = datetime.datetime.now()\n",
    "matching_set_minimal = minimal_matching(sum_weighted_graph)\n",
    "timing_match = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"The Minimal Matching Set is:\", matching_set_minimal, \"\\n\")\n",
    "print(\"---- Timing for Matching (Done on the graph constructed with the treshold constraint) ----\")\n",
    "print(timing_match,\"seconds\")\n",
    "print(\"The number of edges in the graph is:\", sum_weighted_graph.number_of_edges(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(sum_weighted_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Constructs a maximal bipartite graph of the given two tables according to the treshold similarity.\n",
    "The bipartite matching graph only includes those that have passed a certain similarity treshold.\n",
    "The similarity metric takes into account the **values** in this implementation\n",
    "\n",
    "Input: Any 2 files in any format\n",
    "Output: A Bipartite Graph with Maximal Weights\n",
    "\"\"\"\n",
    "def edited_valcomp_construct_graph(file_one, file_n, col_to_dup, treshold_decimal):\n",
    "    table_a_unprocessed = one_to_n.convert_df(file_one)\n",
    "    table_b_unprocessed = one_to_n.convert_df(file_n)\n",
    "    bipartite_graph = nx.Graph()\n",
    "    \n",
    "    table_a_unprocessed = one_to_n.create_duplicates(table_a_unprocessed, col_to_dup, 3) # Assuming that the user inputs 3 duplicates\n",
    "\n",
    "    table_a = one_to_n.make_dict(table_a_unprocessed)\n",
    "    table_b = one_to_n.make_dict(table_b_unprocessed)\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    for key1, val1 in table_a.items():\n",
    "        comp_point_1 = val1[0].split(\"_\")[0]\n",
    "\n",
    "        id1 = str(key1) + '_'+ str(comp_point_1) + '_1'\n",
    "        for key2, val2 in table_b.items():\n",
    "\n",
    "            comp_point_2 = val2[0]\n",
    "            dist = one_to_n.calc_jaccard(str(comp_point_1).lower(),str(comp_point_2).lower())\n",
    "            i+=1\n",
    "            # print(\"first is: \", comp_point_1, \"second is:\", comp_point_2, \"distance is:\", dist)\n",
    "            if i%100000 == 0:\n",
    "                print(str(round(100*i/len(file_one)/len(file_n),2))+'% complete')\n",
    "#             if dist >= treshold_decimal:\n",
    "                \n",
    "                #add value to identifier to disitnguish two entries with different values\n",
    "            id2 = str(key2) + '_' + str(comp_point_2) + '_2'\n",
    "                \n",
    "            num1 = re.sub(\"[^0-9]\", \"\", str(val1[3]))\n",
    "            num2 =re.sub(\"[^0-9]\", \"\", str(val2[3]))\n",
    "                \n",
    "            add_weight = float(num1) + float(num2)\n",
    "                \n",
    "            bipartite_graph.add_edge(id1, id2, weight=add_weight)\n",
    "                #edit distance and weight should be inv. prop.\n",
    "                #also adding 1 to denom. to prevent divide by 0\n",
    "                # add 1,2 to distinguish two key-value tuples belonging to different tables\n",
    "#             else:\n",
    "#                 continue\n",
    "            \n",
    "    return bipartite_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "bipartite_graph_result = edited_valcomp_construct_graph(table_a, table_b, \"title\", 0.5)\n",
    "timing_tresh = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"---- Timing for Graph Construction with Treshold Constraint ----\")\n",
    "print(timing_tresh,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bipartite_graph_result.edges())\n",
    "# edited_weight_graph = SUM_edit_edge_weight(bipartite_graph_result)\n",
    "# print(nx.number_connected_components(bipartite_graph_result))\n",
    "# print(list(nx.connected_components(bipartite_graph_result)))\n",
    "# print(list(bipartite_graph_result.edges()))\n",
    "# print(list(nx.connected_components(bipartite_graph_result)))\n",
    "# remaining = bipartite_graph_result.edges() - nx.connected_components(bipartite_graph_result)\n",
    "# print(\"The number of edges in the graph is:\", bipartite_graph_result.number_of_edges(), \"\\n\")\n",
    "# print(\"\\n\\n 'SUM' MINIMAL MATCHING RESULTS:\")\n",
    "# print(nx.bipartite.is_bipartite(bipartite_graph_result))\n",
    "print(nx.is_connected(bipartite_graph_result))\n",
    "now = datetime.datetime.now()\n",
    "matching_set_minimal = nx.algorithms.bipartite.matching.minimum_weight_full_matching(bipartite_graph_result)\n",
    "timing_match = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"The Minimal Matching Set is:\", matching_set_minimal, \"\\n\")\n",
    "print(\"---- Timing for Matching (Done on the graph constructed with the treshold constraint) ----\")\n",
    "print(timing_match,\"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(remaining))\n",
    "print(inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(bipartite_graph_result.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
