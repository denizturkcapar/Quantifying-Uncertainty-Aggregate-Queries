{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Matching - Bipartite Matching, Naive Matching, Simulation Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bipartite Graph Maximal-Minimal Matching Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "sys.path.insert(0, '../src')\n",
    "import one_to_n\n",
    "\n",
    "import datetime\n",
    "import textdistance\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27% complete\n",
      "4.55% complete\n",
      "6.82% complete\n",
      "9.1% complete\n",
      "11.37% complete\n",
      "13.65% complete\n",
      "15.92% complete\n",
      "18.19% complete\n",
      "20.47% complete\n",
      "22.74% complete\n",
      "25.02% complete\n",
      "27.29% complete\n",
      "29.57% complete\n",
      "31.84% complete\n",
      "34.11% complete\n",
      "36.39% complete\n",
      "38.66% complete\n",
      "40.94% complete\n",
      "43.21% complete\n",
      "45.49% complete\n",
      "47.76% complete\n",
      "50.03% complete\n",
      "52.31% complete\n",
      "54.58% complete\n",
      "56.86% complete\n",
      "59.13% complete\n",
      "61.4% complete\n",
      "63.68% complete\n",
      "65.95% complete\n",
      "68.23% complete\n",
      "70.5% complete\n",
      "72.78% complete\n",
      "75.05% complete\n",
      "77.32% complete\n",
      "79.6% complete\n",
      "81.87% complete\n",
      "84.15% complete\n",
      "86.42% complete\n",
      "88.7% complete\n",
      "90.97% complete\n",
      "93.24% complete\n",
      "95.52% complete\n",
      "97.79% complete\n",
      "---- Timing for Graph Construction with Treshold Constraint ----\n",
      "18.329041 seconds\n"
     ]
    }
   ],
   "source": [
    "table_a = one_to_n.lat_convert_df(\"../Amazon-GoogleProducts/Amazon.csv\")\n",
    "\n",
    "table_b = one_to_n.lat_convert_df(\"../Amazon-GoogleProducts/GoogleProducts.csv\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "bipartite_graph_result = one_to_n.valcomp_treshold_updated_maximal_construct_graph(table_a, table_b, \"title\", 0.5)\n",
    "timing_tresh = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"---- Timing for Graph Construction with Treshold Constraint ----\")\n",
    "print(timing_tresh,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph Construction is a time-expensive calculation, but ideally a user does not need to run graph construction more than once.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bipartite_graph_result.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def SUM_edit_edge_weight(bip_graph):\n",
    "    for u,v,d in bip_graph.edges(data=True):\n",
    "        val_tuple_1 = u.split(\"_\")\n",
    "        val_tuple_2 = v.split(\"_\")\n",
    "        \n",
    "        val1 = re.sub(\"[^0-9]\", \"\", val_tuple_1[2])\n",
    "        val2 =re.sub(\"[^0-9]\", \"\", val_tuple_2[2])\n",
    "\n",
    "        d['weight'] = float(val1) + float(val2)\n",
    "\n",
    "    return bip_graph\n",
    "\n",
    "sum_weighted_graph = SUM_edit_edge_weight(bipartite_graph_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUM Maximal Matching Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 'SUM' MAXIMAL MATCHING RESULTS:\n",
      "---- Timing for Matching (Done on the graph constructed with the treshold constraint) ----\n",
      "3.787009 seconds\n",
      "The number of edges in the graph is: 1215 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n 'SUM' MAXIMAL MATCHING:\")\n",
    "now = datetime.datetime.now()\n",
    "matching_set_maximal = nx.algorithms.matching.max_weight_matching(sum_weighted_graph)\n",
    "timing_match = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"---- Timing for Matching (Done on the graph constructed with the treshold constraint) ----\")\n",
    "print(timing_match,\"seconds\")\n",
    "print(\"The number of edges in the graph is:\", sum_weighted_graph.number_of_edges(), \"\\n\")\n",
    "\n",
    "\n",
    "# print(\"The Maximal Matching Set is:\", matching_set_maximal, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bipartite Matching Performance (Maximal Matching Case): {'false positive': 0.39, 'false negative': 0.68, 'accuracy': 0.42}\n"
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "from Matching import core\n",
    "from Matching import analyze\n",
    "from Matching import matcher\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "def eval_graph_matching(match_results):\n",
    "    results_tuple = []\n",
    "    for (val1, val2) in match_results:\n",
    "        id1 = val1.split(\"_\")[0]\n",
    "        id2 = val2.split(\"_\")[0]\n",
    "        if id1.startswith(\"http\"):\n",
    "            results_tuple.append((id2, id1))\n",
    "        else:\n",
    "            results_tuple.append((id1,id2))\n",
    "    return results_tuple\n",
    "\n",
    "graph_matching_outcome = eval_graph_matching(matching_set_maximal)\n",
    "# print(graph_matching_outcome)\n",
    "print('Bipartite Matching Performance (Maximal Matching Case): ' + str(core.eval_matching(graph_matching_outcome)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Matching Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/denizturkcapar/Desktop/Data Research/Research-Bipartite-Matching-Problem/experiments\n",
      "Loaded catalogs.\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "\n",
    "amzn = core.amazon_catalog()\n",
    "goog = core.google_catalog()\n",
    "print('Loaded catalogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing compare all match (edit distance)...\n",
      "Naive Edit Distance Matching computation time taken:  53.383402  seconds\n",
      "Compare All Matcher (Edit Distance) Performance: {'false positive': 0.72, 'false negative': 0.7, 'accuracy': 0.29}\n",
      "Performing compare all match (jaccard distance)...\n",
      "Naive Jaccard Matching computation time taken:  33.897103  seconds\n",
      "Compare All Matcher (Jaccard Distance) Performance: {'false positive': 0.45, 'false negative': 0.42, 'accuracy': 0.57}\n"
     ]
    }
   ],
   "source": [
    "print('Performing compare all match (edit distance)...')\n",
    "now = datetime.datetime.now()\n",
    "compare_all_edit_match = matcher.matcher(amzn,goog,editdistance.eval, matcher.all)\n",
    "naive_time_edit = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"Naive Edit Distance Matching computation time taken: \", naive_time_edit, \" seconds\")\n",
    "print('Compare All Matcher (Edit Distance) Performance: ' + str(core.eval_matching(compare_all_edit_match)))\n",
    "\n",
    "\n",
    "\n",
    "print('Performing compare all match (jaccard distance)...')\n",
    "now = datetime.datetime.now()\n",
    "compare_all_jaccard_match = matcher.matcher(amzn,goog,analyze.jaccard_calc, matcher.all)\n",
    "naive_time_jaccard = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"Naive Jaccard Matching computation time taken: \", naive_time_jaccard, \" seconds\")\n",
    "print('Compare All Matcher (Jaccard Distance) Performance: ' + str(core.eval_matching(compare_all_jaccard_match)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Sampling Matching Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing random sample match (edit distance)...\n",
      "Simulation-Based Edit Distance Matching computation time taken:  32.660594  seconds\n",
      "Random Sample Matcher (Edit Distance) Performance: {'false positive': 0.88, 'false negative': 0.88, 'accuracy': 0.12}\n",
      "Performing random sample match (jaccard distance)...\n",
      "Simulation-Based Jaccard Matching computation time taken:  24.757538  seconds\n",
      "Random Sample Matcher (Jaccard Distance) Performance: {'false positive': 0.79, 'false negative': 0.78, 'accuracy': 0.21}\n"
     ]
    }
   ],
   "source": [
    "print('Performing random sample match (edit distance)...')\n",
    "now = datetime.datetime.now()\n",
    "compare_all_edit_match = matcher.matcher(amzn,goog,editdistance.eval, matcher.random_sample, sample_size)\n",
    "sim_time_edit = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"Simulation-Based Edit Distance Matching computation time taken: \", sim_time_edit, \" seconds\")\n",
    "print('Random Sample Matcher (Edit Distance) Performance: ' + str(core.eval_matching(compare_all_edit_match)))\n",
    "\n",
    "print('Performing random sample match (jaccard distance)...')\n",
    "now = datetime.datetime.now()\n",
    "compare_all_jaccard_match = matcher.matcher(amzn,goog,analyze.jaccard_calc, matcher.random_sample, sample_size)\n",
    "sim_time_jaccard = (datetime.datetime.now()-now).total_seconds()\n",
    "print(\"Simulation-Based Jaccard Matching computation time taken: \", sim_time_jaccard, \" seconds\")\n",
    "print('Random Sample Matcher (Jaccard Distance) Performance: ' + str(core.eval_matching(compare_all_jaccard_match)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Findings: \n",
    "\n",
    "- Matching on a bipartite graph took significantly less time than the naive and random sampling matching approach for the given similarity treshold of 0.5 for jaccard similarity.\n",
    "\n",
    "- Bipartite Matching approach performed similar to the Naive jaccard matching in terms of accuracy.\n",
    "    - Bipartite Matching Accuracy: 0.42\n",
    "    - Naive Jaccard Matching Accuracy: 0.57\n",
    "    \n",
    "- Bipartite Matching seemed to perform better considering the accuracy versus time-expense tradeoff.\n",
    "\n",
    "Note: Jaccard similarity fit better for this task so jaccard was used in the graph matching.\n",
    "\n",
    "### Possible Next Step\n",
    "\n",
    "- Comparing the thresholds of [min_sum, max_sum] for the SUM operation for Naive, Simulation-Based, and Graph Matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
